\documentclass[fleqn]{report}
\usepackage{geometry}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{multicol}
\usepackage{blindtext}
\usepackage{color}
\usepackage[fontsize=16pt]{fontsize}
\usepackage{lipsum}
\usepackage{pgfplots}
\usepackage{physics}
\usepackage{mathtools}
\usepackage[makeroom]{cancel}
\usepackage{ulem}

\setlength{\columnsep}{1cm}
\addtolength{\jot}{0.1cm}
\def\columnseprulecolor{\color{blue}}
\date{Fall 2024}

\newcommand{\textoverline}[1]{$\overline{\mbox{#1}}$}

\newcommand{\hp}{\hspace{1cm}}

\newcommand{\del}{\partial}

\newcommand{\pdif}[2]{ \frac{\partial #1}{ \partial #2} }

\newcommand{\pderiv}[1]{ \frac{\partial}{ \partial #1} }

\newcommand{\comment}[1]{}

\newcommand{\equations} [1] {
\begin{gather*}
#1
\end{gather*}
}

\newcommand{\twovec}[2]{ 
\begin{pmatrix}
#1 \\ 
#2
\end{pmatrix}
}

\title{MATH 257}
\author{Aiden Sirotkine}

\begin{document}

\pagestyle{fancy}
\maketitle
\tableofcontents
\clearpage

\chapter{MATH 257}
My laptop died and I skipped some lectures to go to a part time 
job fair but I know every basic thing about matrices and vectors 
so I should be fine 

\chapter{Column Vectors and Basis Vectors} 
If you take the columns of a vector, then you get a couple vectors 
that span a space.

Solving a linear system is the same as finding the linear combinations 
that equal a certain result

\section{Matrix Vector Multiplication}
\[
\begin{bmatrix}
    c_1 && c_2 && c_3
\end{bmatrix}
\begin{bmatrix} a \\ b \\ c \end{bmatrix} =
a c_1 + b c_2 + c c_3
\]

\section{Transformations}
You can multiply a vector by a matrix to transform it in a certain 
way

\subsection{Rotation}
\[
\begin{bmatrix}
\cos \theta && - \sin \theta \\
\sin \theta && \cos \theta
\end{bmatrix}
\]

\section{Elementary Matrices}
An elementary matrix is a matrix gotten by doing a single elementary 
row operation on the identity matrix.

To find the inverse of an elementary matrix, you just do the 
opposite of the row operation to an identity matrix.

\section{Invertible Matrices}
Suppose $A$ and $B$ are invertible. Then:
\begin{itemize}
    \item
    $A^{-1}$ is invertible then $(A^{-1})^{-1} = A$
    \item
    $AB$ is invertible if $(AB)^{-1} = A^{-1} B^{-1}$
    \item
    $A^T$ is invertible iff $(A^T)^{-1} = (A^{-1})^{T}$
\end{itemize}


\section{LU Decomposition}
idk what it is but it's probably important

It stands for lower upper decomposition.

You can find a upper and lower triangular matrices $L$ and $U$
such that $A = LU$

You know a matrix can be decomposed if you can put the matrix
in echelon form with just row operations from a higher row to 
a lower row. 

\subsection{How To Steps}
\begin{enumerate}
    \item 
    Row reduce
    \item
    Find elementary matrices $E_1, E_2 \ldots$
    \item 
    L = $E^{-1}_1, E^{-1}_2, \ldots$
    \item 
    U = echelon form of original matrix that you already calculated
\end{enumerate}

\subsection{Solving a thingy}
to solve $Ax = b$, you can solve $Ux = c$ such that $Lc = b$.


\subsection{Inner Product}
\[
v \cdot w = v^{T} w
\]

\subsection{Norm}
\[
||v|| = \sqrt{v \cdot v}
\]

\subsection{Distance}
\[
\textrm{dist}(v, w) = ||v - w|| 
\]

\section{Orthogonality}
if twe vectors are orthogonal or perpendicular to each other, then 
\[
v \cdot w = 0
\]

\subsection{Pairwise Orthogonal}
A set of vectors is pairwise orthogonal if they are 
all orthogonal to each other. 

\subsection{Orthonormal Set}
A set of unit vectors that are all orthogonal to each other. 

\section{Subsets/ Subspaces}
A non-subset $H$ of $\mathbb{R}^n$ is a subspace of $\mathbb R^n$
if it satisfies the two following:
\begin{itemize}
    \item 
    if $u, v \in H$, then $u + v \in H$ 

    (closed under addition)
    \item 
    if $u \in H$ and $c$ is scalar, then $cu \in H$

    (closed under scalar multiplication)
\end{itemize}

subspaces are pretty useful

\subsection{Column Space}
The space created by spanning the columns of a matrix

\subsection{Null Space}
The space created by all the solutions of the equation $Ax = 0$. 































\end{document}